---
layout: post
title: TDD笔记
category: code
tag: tdd
---

## 缘起

本文是对tdd或单元测试的一个小结.以前尝试过很多次,但都没有具体的文字记录下来,导致的结果就是不停的对相同的概念和流程进行重复学习

重点是掌握怎么写单元测试

其实单元测试是比较容易写的(how),比如利用gtest框架,但写什么,测试什么(what)是个比较难搞的问题.平时工作接触到的代码而言,感觉都非常难于测试,如何分解重构历史代码,如何编写新的功能和测试代码,这些方面都不是很了解,所以希望通过本次的学习,至少有个明确的认识

本文是对[Modern C++ Programming with Test-Driven Development][tdd book]的部分笔记,夹杂一些个人想法

## TDD循环

典型的TDD是由一系列类似的循环(cycle)构成的,每个循环分为失败(Red)/成功(Green)/重构(Refactor)三个部分

* **Red** 按需求写一个test,并且保证该test会失败
* **Green** 编写代码,使新test和以前所有的test都成功
* **Refactor** 在保证所有test成功的前提下,对现有代码进行重构

基本的流程就是上述循环的不断进行,类似软件工程当中所说的**迭代开发**,每次循环都会前进一小步,然后根据这一小步,来调整前进的方向

## TDD单步思考

TDD循环的每个步骤中,都有一些重要问题需要思考

* **编写test(Red)** 目前系统需要开发的最小的功能是什么?该功能是否已经存在呢?该功能可以很容易的利用当前系统的接口实现么?该功能足够小,并且可以用合适的test名字表达么?
* **保证新test失败(Red)** 该test失败了么?没失败的话,原因是什么?是否以前的开发步子太大了呢?是否断言的问题是错误的呢?
* **让新test成功(Green)** 代码除了让test成功之外,有没有意外的添加其他功能呢?是否过早的考虑到了性能/风格之类的非本步骤的问题呢?
* **让所有test成功(Green)** 以前的test是否还能成功呢?不成功的话,是哪里导致的?新加代码是否修改了原有行为?是否本次开发的功能太大了呢?或者需求是矛盾的呢?
* **重构代码(Refactor)** 代码风格是否统一呢?系统的结构是否合理呢?代码中是否有bad smell?系统迭代的方向是否合适呢?
* **确保test仍然成功(Refactor)** 没有成功的话,是什么原因导致的呢?

TDD循环是需要严格遵守的,一个步骤没有完成,是绝对不能进行下一步的,而且,步骤是要小且单一的,不要妄图同时完成很多任务,并且要保证通过所有test

## 三条规则

1. 没有test失败,就不需要编写新的代码
2. 编写一个足以失败的test即可(编译失败也算)
3. 编写代码,仅能让失败的test通过即可

步骤1表示,test集是明确和完善开发需求的唯一准则,所有test都成功了,就表明所有需求满足,也就不需要开发(当然,重构还是可以的).而且在后续的开发中,也是通过test集来保证需求一直是满足的(即不会break以前的需求).同时也说明,添加功能,第一步是编写对应的test,无test,无开发

步骤2的重点在于**足以**,即编写的test越小越好(当然不一定指test的代码多少),迭代的步骤越小越不容易出错,越容易开发.个人感觉,很好的指标是test代码行数和编译器的error/warning数量,行数一般不要多于5-6行,仅包涵一个关键断言即可,error/warning也只能有一个

步骤3的重点在于**仅能**,即编写足够的代码让这**唯一**的test成功即可,不多不少.太少的话,肯定无法让test成功,太多的话,肯定是实现了多余的功能,但这些功能又没有相关的test来保证,所以可以说是做了无用功了

当然,这些规则并不是教条,比如在很大的C++代码集中,编译成本很高,可能编译失败就无法很实际的作为失败的test了.

开发是件艺术的工作,如果真的有一步一步的确定的规则的话,那岂不是可以编写一个算法,让计算机来帮我们搞定了么?

## 新test没有失败

一般来说,编写新test是为了给系统增加新的功能,但在实际开发中,会碰到这样的情况,新test直接成功了.这大部分时间不是个好的情况,一般来说,可以从以下角度来分析看看

* **没有运行新test** 这种情况的话比较silly,编写的新test,但是没有把新test包含进去.我们可以通过比对运行的test名称和数量来判断
* **被测试的代码有误** 比如代码build就失败了,所以可能没有test的情况(所以就没有test失败),再比如说,重构代码中,test集编译时连接了旧的代码,此时自然肯定是成功的.这就需要谨慎的处理各种编译信息,对于各种warning/error和编译路径都需要看清
* **错误的test** 新test要引入功能,需要断言来确保功能的正确,但是如果我们错误理解,或错误编写了断言逻辑,那么有可能本来错误的test,就直接成功pass了.这个时候,需要重新对照需求/todo list,看测试逻辑是否有误(这也是为什么test需要小的原因,小才容易发现逻辑上的问题)
* **系统假设错误** 新test可能依赖于系统的其他部分,而我们做出的test逻辑的依赖可能和系统的假设不同.比如test依赖的接口的功能,可能不止我们想象的一样,所以依赖于此,使我们做了错误假设.这个一般比较容易验证
* **测试顺序错误** 系统功能之间可能有重叠(比如需求不明或者功能切割有误,或者迭代时选择方向有误),以文中例子而言,isEmpty()和size()的功能上是有耦合的(size() == 0 <=> isEmpty() == true),当开发任一功能时,很可能就直接把另一个功能直接实现了,当测试另一个功能时,可能就是直接pass.此处的解决方案有二,一是回顾下test集,思考是否有必要加入该test,比如相互重叠甚至重复的test是可以去掉的;二是严格遵守Green原则,不要过度开发代码,**仅仅**让test成功即可,比如isEmpty就可以使用is_empty_来表示,而不是更通用的size_,以后重构时再考虑这些问题
* **测试功能耦合** 同上一个角度类似,此处表示的是功能的耦合,不管是出于需求也好,实现角度也好,功能之间有时会有耦合的地方,可能新test测试的正好是这些耦合功能,所以直接就成功了.此时的处理方法就是用test来保证这种耦合性.比如新建isEmptyWhenSizegt0来确保二者的关系,这样就可以一劳永逸的放心了
* **过度编码** 也就是说在修复旧test集时,已经将其他非test功能一并实现了,所以此时新test直接成功了.过度编码并不是说不对,因为可能不论从设计还是开发角度来看,有些test非常trival(比如缺少类/接口导致的编译错误),我们直接倾向于一下子就搞定,但这样就会带来一系列不需要或者没有test覆盖的功能添加到系统中来,这个问题比多花些时间来小步骤迭代前进要严重的多.所以还是要小步前进,严格遵循Red/Green/Refactor的循环来做
* **信心测试** 除去新加功能外,test集还可以帮助我们增强多系统的信心,比如功能涉及某一复杂算法,本来已经通过所有的test集了,但我们不放心,此时,我们可以添加新的test来验证算法的正确性.不过注意,此时我们运行测试前就预计会成功,没有成功反而说明原先test集不完善,属于验证性质的测试

除去以上的问题,时刻要牢记TDD三段循环迭代的方式,test要足够小,实现代码也要足够小(仅仅让test成功即可),只有迭代步骤小才能保证系统功能的正确性和系统结构的合理性

(恩,号称:步子大了,容易扯着蛋)

## 实行TDD的准则

有一些抽象的原则,可以在实行TDD时,确保不会偏离方向,或者引入不必要的错误.需要注意的是,TDD不只是测试系统功能,还可以辅助系统设计的演化

### 渐进迭代




[tdd book]: http://book.douban.com/subject/25713562/
