---
layout: math
title: 算法之美第二章 习题
category: algorithm
tag: algorithms
---

## 前注

暂时忽略所有的fft题目,这部分和复数搭边的还没有搞得太懂,暂时放下先

## 2.1

在上一篇中我们已经看到了几种不同的乘法分治方法,可以简单的进行unroll即可计算

分治算法不难想到,关键是如何像书本中那样,得到4变3的优化.我这里也没有太多好的想法,大体上可能还是跟着主定理,想方法减少子问题规模或者子问题数量,但当初的灵机一动,是如何也想不出来的

[jeff的笔记][jeff]上讲过一些当年的背景趣闻,可以参看一下

## 2.2

问题即证明$\exists k, n \leq b ^ k \leq b n$,两边同时对b取对数,得$\log _ b n \leq k \leq \log _ b (b n) = \log _ b n + 1$,可以看到,不等式两边差一,所以中间必然存在满足条件的整数k

ps:遇到类似带有乘幂的问题,一般有两个想法,一是利用乘幂的性质($a ^ x a ^ y = a ^ {x + y}, (a ^ x) ^ y = a ^ {x y}$),二是利用对数,转化成对应的四则运算.二者本质是一样的,只是对数比较方便判断和比较而已

## 2.3

本题引入了另一种求解递归式的方法,相比递归树而言,这个更适合计算,但也略微不太直观

需要注意的是,这些递推公式都没有递归终点,这样的公式是完整的,这里可以假设$T(1) = O(1)$,但实际的操作过程中,需要根据实际情况进行分析,关键是**永远不要忘了递归终点**

### a

展开对应的递推式,得

$$
T(n) = 3 T(n / 2) + c n = 9 T(n / 4) + c n (1 + \frac{3}{2}) = 27 T(n / 8) + c n (1 + \frac{3}{2} + \frac{9}{4}) = \dots = 3 ^ k T(n / 2 ^ k) + c n (1 + \frac{3}{2} ^ 1 + \cdots + \frac{3}{2} ^ {k - 1})
T(n) = 3 ^ k T(n / 2 ^ k) + 2 c n (\frac{3}{2} ^ {k - 1} - 1)
$$

$k = \log n$可以最后化简公式,得$T(n) = n ^ {\log _ 2 3} O(1) + \frac{4}{3} c n ^ {\log _ 2 3} - 2 c n = O(n ^ {\log _ 2 3})$

同主定理的结论一致

ps:计算复杂度,同以前的高数类似,关键不仅在于变换形式,还有适当情况下的忽略和补位,这个还是需要多多积累经验才能看到的


### b

$T(n) = T(n - 1) + c = T(n - 2) + 2 c = \dots = T(1) + c n = O(n)$

ps:上述两个问题,除了$T(1)$的假设之外,其实我们还有一个假设,即每次展开的常数是相同的(都是c),但在实际问题中,这个也是不一定成立的,所以还是需要谨慎

## 2.4

算法A: $T(n) = 5 T(n / 2) + O(n) = O(n ^ {\log _ 2 5})$

算法B: $T(n) = 2 T(n - 1) + O(1) = O(2 ^ n)$

算法C: $T(n) = 9 T(n / 3) + O(n ^ 3) = O(n ^ 3)$

要选择的话,应该选择算法A

## 2.5

### a

$T(n) = 2 T(n / 3) + 1 = O(n ^ {\log _ 3 2})$

### b

$T(n) = 5 T(n / 4) + n = O(n ^ {\log _ 4 5})$

### c

$T(n) = 7 T(n / 7) + n = O(n \log n)$

### d

$T(n) = 9 T(n / 3) + n ^ 2 = O(n ^ 2 \log n)$

### e

$T(n) = 8 T(n / 2) + n ^ 3 = O(n ^ 3 \log n)$

### f

$T(n) = 49 T(n / 25) + n ^ {3 / 2} \log n = O(n ^ {3 / 2} \log n)$

### g

$T(n) = T(n - 1) + 2 = O(n)$

### h

$T(n) = T(n - 1) + n ^ c = O(n ^ {c + 1})$

计算过程比较巧妙,可以参照1.4的解法

$$
T(n) = \sum ^ n i ^ c \leq \sum ^ n n ^ c = n n ^ c = n ^ {c + 1} = O(n ^ {c + 1})
$$

$$
T(n) = \sum i ^ c \geq \sum ^ {n / 2} \frac{n}{2} ^ c = \frac{n}{2} \frac{n}{2} ^ c = 1 / {2 ^ {c + 1}} n ^ {c + 1} = \Omega (n ^ {c + 1})
$$

所以得到了结论

### i

$T(n) = T(n - 1) + c ^ n = \sum c ^ i$

若$c = 1$,则$T(n) = O(n)$

若$c > 1$,则$T(n) = \frac{c ^ n - 1}{c - 1} = O(c ^ n)$

### j

$T(n) = 2 T(n - 1) + 1 = 2 ^ n + \sum 2 ^ i = 2 ^ {n + 1} - 1 = O(2 ^ n)$

### k

$T(n) = T(\sqrt {n}) + 1 = T(\sqrt[4] {n}) + 2 = T(\sqrt[2 ^ k] {n}) + k$

假设$T(c) = O(1)$,此时$\sqrt[2 ^ k] {n} = c \Rightarrow k = \log \log _ c n = O(\log \log n)$,所以$T(n) = O(\log \log n)$

## 2.6

(暂时忽略)

## 2.7

$$
Sum = \sum \omega ^ i = 
\left
\\\{
\begin{aligned}
1 & \, & \omega = 1 \\\\
\frac{1 - \omega ^ n}{1 - \omega} = 0 & \, & \omega \neq 1
\end{aligned}
\right.
$$

$$
Prod = \prod \omega ^ i = \omega ^ {\sum i} = \omega ^ {\frac{n (n - 1)}{2}} = 
\left
\\\{
\begin{aligned}
(\omega ^ n) ^ {\frac{n - 1}{2}} = 1& \, & n为奇数 \\\\
(\omega ^ {\frac{n}{2}}) ^ {n - 1} = -1 & \, & n为偶数
\end{aligned}
\right.
$$

ps:复数计算是个很头痛的地方,需要谨慎

## 2.8-2.10

(暂时忽略)

## 2.11

设$Z = X Y$,根据矩阵乘法规则,有$Z(i, j) = \sum X(i, k) Y(k, j)$,然后分块来看结果矩阵

以左上角为例,$i \in [0, n / 2), j \in [0, n / 2)$,对应的分别是A/B和E/G(因为$k \in [0, n)$),根据乘法法则,可以看出左上角的结果是$A E + B G$

剩余可以以此类似可得证明

## 2.12

类似复杂度分析,$f(n) = 2 f(n / 2) + 1 = \Theta (n)$

## 2.13

### a

可以画图看看,有$B _ 3 = 1, B _ 5 = 2, B _ 7 = 5$

如果n为偶数,则无法构成满二叉树了,因为除去根节点外,每层的节点都是偶数(包括0),所以总的节点数是奇数

### b

递归的表示已经有了($B _ n$),现在来考虑问题的分解

#### 减2

一个自然的想法是将问题规模减2,即$B _ n \Rightarrow B _ {n - 2}$,以此来得到子问题

* 递归终点 a中已经有了几个基本case,为了简单期间,我们可以设$B _ 1 = 1$作为终点
* 合并子问题 已知$B _ {n - 2}$,如何求解$B _ n$呢?一个自然的想法是给多出的2个节点找到一个父节点即可,此处的父节点就是原满二叉树$B _ {n - 2}$的叶子节点.这样,我们就需要计算出可能的叶子节点的数目,就是新的满二叉树的数目

但是存在一个细节,即相同的满二叉树只能算作一个.比如计算$B _ 7$时,三层的满二叉树有两种构建方法(二层左/右),但这样的二叉树只能计算一个.所以我们还需要求解类似对称/镜像的二叉树数量

这样看来,就比较复杂了,我们可以换换思路

#### 分子树

树形结构的特点,有一个自然的减小规模的方式,即以根节点拆分为两个子树

* 递归终点 此处最自然的就是$B _ 1 = 1$的情况,作为终点
* 合并子问题 子问题是什么呢?我们必须表达成$B _ x$的形式(问题性质必须类似).没有好的办法之前,枚举是唯一的方法.节点总数为n,左子树节点从1到n-1(设为i),那么右子树节点数相应的是n-1-i.已知左右子树的数目,原树的数目利用乘法原理即可得到,有$B _ n = \sum B _ i B _ {n - 1 - i}$

这样的合并子问题是没有重复的,因为左右子树数目不一样,必然是不同的满二叉树,没有"减2"时的重复

ps:看$B _ n$的递推公式,可以联想到类似的Catalan数,不同的是$B _ n$对于偶数n的结果为0,因此无法直接利用Catalan数的公式和性质

先补充一下该数的性质.$C _ n = \sum C _ i C _ {n - 1 - i} = \frac{4 n - 2}{n + 1} C _ {n - 1} = \frac{1}{n + 1} {2 n \choose n}$,

我们怎么把$B _ n$和$C _ n$联系起来呢?把$B _ n$的下标中的偶数去掉即可,即

$$
B _ n = B _ {2 k + 1} = \sum _ 0 ^ {k - 1} B _ {2 i + 1} B _ {(2 k + 1) - 1 - (2 i + 1)} = \sum _ 0 ^ {k - 1} B _ {2 i + 1} B _ {2 (k - 1 - i) + 1}
$$

同Catalan数进行比较

$$
C _ k = \sum _ 0 ^ {k - 1} C _ i C _ {k - 1 - i}
$$

而且,$B _ 1 = 1 = C _ 0$,可得,$B _ {2 k + 1} = C _ k$,这样我们就可以将已知的Catalan数性质公式拿来直接使用了

pps:$\sum$求和时,有两个关键点,一个是求和的式子(内部),另一个是求和定义域.在变换时,两个都要注意,第一次变换的时候,我也是很长时间不得要领,混淆了很长一段时间,还是数学功底差啊

ppps:遇到间隔求和(类似本题的奇数项),一个常见的方法是将间隔变换成连续,这样更容易发现规律

### c

由b可知,$B _ {2 k + 1} = C _ k = \frac{4 k - 2}{k + 1} C _ {k - 1} = \frac{4 k - 2}{k + 1} B _ {2 k - 1}$,当n一定时,$B _ n \geq 4 B _ {n - 1}$,所以满足$B _ n = 2 ^ {\Omega {n}}$

## 2.14

问题比较简单,但是要从分治的角度来思考这个问题

问题的表示可以先简单的表达为当前元素的个数,即$(n)$,然后考虑如何减小问题规模

### 规模减1

即每次首先挑出一个元素,然后递归的解决规模小1的问题

* 递归终点 自然的想法是$(1)$,此时什么都不需要操作
* 合并子问题 目前已知$(n - 1)$和一个元素(假设是$a _ n$),此时,只需要遍历已知的$(n - 1)$序列,把和$a _ n$重复的元素排除掉,那么剩下的就是无重复序列了

复杂度应该是$T(n) = T(n - 1) + O(n) = O(n ^ 2)$,哈哈,不满足要求诶.

### 规模减半

还是惯用的减小规模的办法,将原序列分解为两个子序列,分别处理再合并

* 递归终点 同样的是$(1)$,此时不需要处理
* 合并子问题 已知2个$(n / 2)$,即2个无重复元素的序列,此时,唯一可能的重复出现在这两个序列之间,那么分别遍历,然后将重复元素排除饥渴

此时复杂度是$T(n) = T(n / 2) + O(n ^ 2) = O(n ^ 2)$,哈哈,还是不满足要求

### 思考

为什么没有得到一个满足要求的算法呢?可以看到,简单的减小问题规模,而不做额外的处理,其结果和bf直接遍历基本没有什么区别.我们需要做一些额外的工作,利用每次分解/合并的信息,来优化算法

#### 优化1

规模减半的解法中,合并代价是$O(n ^ 2)$,因为处理的是无序序列,如果两个子序列有序,那么只需要$O(n)$就可以完成目标了.限制为有序,则在合并子问题阶段,不仅需要遍历比较,还需要类似mergesort,输出新的有序序列,这个同样是$O(n)$

那么此时的复杂度是$T(n) = 2 T(n / 2) + O(n) = O(n \log n)$,满足条件了

#### 优化2

合并时的处理,同样可以放在分解时进行.类似quicksort,我们不再完全二分,而是将序列分解为一小一大的有序序列块,这样的分解操作需要$O(n)$,那么再处理完各自的子序列后,原序列不可能由重复元素(有序),那么合并也就很trival了

此时的复杂度是$T(n) = O(n) + 2 T(n / 2) = O(n \log n)$,同样满足要求

#### 优化3

规模减一的时候,首先是要遍历序列,判断是否和挑选出来的$a _ n$重复,可以想象到,子问题$(n - 1)$则是挑选出$a _ {n - 1}$,然后重复遍历判断重复.第一次遍历的信息,根本没有在后续使用到,虽然二者遍历的几乎是同一个序列(后续的序列只小不大),一个自然的想法就是先预处理,把序列信息整合起来,使后续可以直接使用

最自然的想法就是利用hashmap,保存元素和出现次数,然后在遍历序列,把唯一的元素跳出即可.(当然,剩下的一些单遍历优化就是边边角角,此处不赘述)

这样的复杂度是$T(n) = O(n)$,但空间复杂度也成了$O(m)$,即hashmap的大小了

### 总结

合并子问题其实不止是合并工作,在合并子问题阶段,已知规模小的问题的解答,即只要规模小于当前的规模,都能得解,那么我们就可以完全任意的来分解问题了.也就是说,主要工作不一定在真正合并的那一刻,也可以在为了合并而分解问题的那一刻

就那mergesort和quicksort来说,mergesort就是随意分解,但合并时复杂(合并承担主要工作),但quicksort则是小心分解,使得合并非常trival(分解承担主要工作).分治法无非就是这两个步骤,在思考合并子问题时,要着重思考两点,一是是否需要仔细分解问题,二是是否需要仔细合并问题.简单的问题可能一个即可,但有的问题则是需要两头开弓才行

预处理在分治算法中,也有很重要的用途.因为分解之后的子问题是原问题的一部分,所以必然由一些性质是共享的,当在分治求解时,发现一些信息在被重复使用/计算,就可以想想能否通过预处理,来优化这部分的时间.当然,最后可能就直接像优化3一样,脱离来分治的路子了,但我们是要解题,所以也是一个好的现象

## 2.15

quicksort/quickselect的分解关键,算法主要维护几个区间:

* [0, small): 小于v
* [small, equal): 等于v
* [equal, big]: 未知
* (big, n - 1]: 大于v


代码如下:

    void partition(vector<int>& S, int v) {
        int small = 0;
        int equal = 0;
        int big = S.size() - 1;
        while (equal <= big) {
            if (S[equal] < v) {
                swap(S[small++], S[equal++]);
            } else if (S[equal] == v) {
                equal++;
            } else {
                swap(S[equal], S[big--]);
            }
        }
    }


## 2.16



[jeff]: http://www.cs.illinois.edu/~jeffe/teaching/algorithms/ "jeff的笔记"
